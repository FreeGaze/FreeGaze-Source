{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import random\n",
    "import copy\n",
    "import packages.baseline_model as baselibe_model\n",
    "import common_functions\n",
    "from skimage import io\n",
    "import cv2\n",
    "import trans_in_rgb\n",
    "import matplotlib.pyplot as plt\n",
    "from jpeg2dct.numpy import load, loads\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBProjectionHead(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    projection head for contrastive learning\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, bias_initializer=tf.keras.initializers.constant(0.01),\n",
    "                                            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                            bias_regularizer=regularizers.l2(1e-4))\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = tf.keras.layers.Dense(256, bias_initializer=tf.keras.initializers.constant(0.01),\n",
    "                                            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                            bias_regularizer=regularizers.l2(1e-4))\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input, training=None):\n",
    "        x = self.dense1(input)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        output = self.dense2(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18_BaseEncoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, layer_params=None, method=\"late_concate\"):\n",
    "        super(Resnet18_BaseEncoder, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        if layer_params is None:\n",
    "            layer_params = [2, 2, 2, 2]\n",
    "        self.y_input_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.cbcr_input_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.layer1_y = make_basic_block_layer(filter_num=64,\n",
    "                                             blocks=1, dimen_match=True) # y:56,56,64\n",
    "        self.cb2_y = make_basic_block_layer(filter_num=128,\n",
    "                                             blocks=1, stride=2) # y:28,28,128\n",
    "        self.cb2_cbcr = tf.keras.layers.Conv2D(filters=128,\n",
    "                                               kernel_size=(1,1),\n",
    "                                               strides=1,\n",
    "                                               padding=\"same\")\n",
    "        self.cb_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.layer4 = make_basic_block_layer(filter_num=512,\n",
    "                                             blocks=2, # 14,14,512\n",
    "                                             stride=2)\n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        y = self.y_input_bn(inputs[0], training=training)\n",
    "        cb_cr = self.cbcr_input_bn(inputs[1], training=training)\n",
    "\n",
    "        y = self.layer1_y(y, training=training) # 56,56,64\n",
    "        y = self.cb2_y(y, training=training) # 28,28,128\n",
    "        cb_cr = tf.nn.relu(self.cb_bn(self.cb2_cbcr(cb_cr), training=training)) #28,28,128\n",
    "        x = tf.concat((y, cb_cr), axis=3) #28,28,256\n",
    "        x = self.layer4(x, training=training) #14,14,512\n",
    "        x = self.avgpool(x)\n",
    "        output = self.flatten(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def make_basic_block_layer(filter_num, blocks, k_size=(3,3), stride=1, dimen_match=False):\n",
    "    res_block = tf.keras.Sequential()\n",
    "    res_block.add(BasicBlock(filter_num, k_size=k_size, stride=stride, dimen_match=dimen_match))\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "        res_block.add(BasicBlock(filter_num, stride=1))\n",
    "\n",
    "    return res_block\n",
    "\n",
    "\n",
    "class BasicBlock(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, filter_num, k_size=(3,3), stride=1, dimen_match=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=k_size,\n",
    "                                            strides=stride,\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=k_size,\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        if stride != 1 or dimen_match is True:\n",
    "            self.downsample = tf.keras.Sequential()\n",
    "            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                       kernel_size=(1, 1),\n",
    "                                                       strides=stride))\n",
    "            self.downsample.add(tf.keras.layers.BatchNormalization())\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        residual = self.downsample(inputs)\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "\n",
    "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47de96e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define hyper parameters\n",
    "batch_size = 128\n",
    "tau = 0.1\n",
    "\n",
    "# Define base encoder and projection head\n",
    "feature_extractor = Resnet18_BaseEncoder()\n",
    "projection_head = RGBProjectionHead()\n",
    "\n",
    "labels = np.load(\"/home/lingyu/MPIIFaceGaze_normalized/MPIIFaceGaze_normalizad/mix_dataset/labels.npy\")\n",
    "left_landmarks = np.load(\"/home/lingyu/MPIIFaceGaze_normalized/MPIIFaceGaze_normalizad/mix_dataset/left_landmarks.npy\")\n",
    "right_landmarks = np.load(\"/home/lingyu/MPIIFaceGaze_normalized/MPIIFaceGaze_normalizad/mix_dataset/right_landmarks.npy\")\n",
    "dataset_size = labels.shape[0]\n",
    "pre_train_data_size = 29992  # images of first 10 subjects\n",
    "print(dataset_size)\n",
    "print(\"self learing on the first 10 subjects, the total number of pretrain images are\", pre_train_data_size)\n",
    "\n",
    "# Define optimizers for contrastive learning\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "# define batch for query and positive\n",
    "query_batch_y = np.zeros((batch_size, 28, 28, 6))\n",
    "query_batch_cbcr = np.zeros((batch_size, 14, 14, 6))\n",
    "positive_batch_y = np.zeros((batch_size, 28, 28, 6))\n",
    "positive_batch_cbcr = np.zeros((batch_size, 14, 14, 6))\n",
    "\n",
    "trans_list = [1, 2]\n",
    "error_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838e01b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# contrastive learning\n",
    "for epoch in range(10000):\n",
    "\n",
    "    index = np.random.choice(pre_train_data_size, batch_size, replace=False)\n",
    "    j = 0\n",
    "    for i in index:\n",
    "        jpeg_file = '/home/lingyu/MPIIFaceGaze_normalized/MPIIFaceGaze_normalizad/mix_dataset/' + str(i) + '.jpg'\n",
    "        img = io.imread(jpeg_file) / 255.\n",
    "        selected_trans = random.sample(trans_list, 2)\n",
    "        noised_image1 = trans_in_rgb.apply_transformation(copy.deepcopy(img), selected_trans[0], left_landmarks[i], right_landmarks[i])\n",
    "        noised_image2 = trans_in_rgb.apply_transformation(copy.deepcopy(img), selected_trans[1], left_landmarks[i], right_landmarks[i])\n",
    "\n",
    "        noised_image1 = trans_in_rgb.apply_transformation(copy.deepcopy(noised_image1), selected_trans[1], left_landmarks[i], right_landmarks[i])\n",
    "        noised_image2 = trans_in_rgb.apply_transformation(copy.deepcopy(noised_image2), selected_trans[0], left_landmarks[i], right_landmarks[i])\n",
    "        \n",
    "        noised_image1 = cv2.resize(noised_image1, (224,224))\n",
    "        noised_image2 = cv2.resize(noised_image2, (224,224))\n",
    "\n",
    "        noised_image1 *= 255\n",
    "        noised_image1 = np.round(noised_image1).astype(np.uint8)\n",
    "        noised_image2 *= 255\n",
    "        noised_image2 = np.round(noised_image2).astype(np.uint8)\n",
    "        io.imsave(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/temp_pic/noised_image1.jpg\", noised_image1)\n",
    "        io.imsave(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/temp_pic/noised_image2.jpg\", noised_image2)\n",
    "\n",
    "        jpeg_noised = \"/home/lingyu/CL_gaze_project/MPIIFaceGaze/temp_pic/noised_image1.jpg\"\n",
    "        dct_y, dct_cb, dct_cr = load(jpeg_noised)\n",
    "        # channel selection\n",
    "        dct_y = np.concatenate((np.concatenate((dct_y[:, :, 0:3], dct_y[:, :, 8:10]), axis=2),\n",
    "                                np.reshape(dct_y[:, :, 16], (28, 28, 1))), axis=2)\n",
    "\n",
    "        dct_cb = np.concatenate((dct_cb[:, :, 0:2], np.reshape(dct_cb[:, :, 8], (14, 14, 1))), axis=2)\n",
    "        dct_cr = np.concatenate((dct_cr[:, :, 0:2], np.reshape(dct_cr[:, :, 8], (14, 14, 1))), axis=2)\n",
    "        cb_cr = np.concatenate([dct_cb, dct_cr], 2)\n",
    "        query_batch_y[j, :, :, :] = dct_y\n",
    "        query_batch_cbcr[j, :, :, :] = cb_cr\n",
    "\n",
    "        jpeg_noised = \"/home/lingyu/CL_gaze_project/MPIIFaceGaze/temp_pic/noised_image2.jpg\"\n",
    "        dct_y, dct_cb, dct_cr = load(jpeg_noised)\n",
    "        # channel selection\n",
    "        dct_y = np.concatenate((np.concatenate((dct_y[:, :, 0:3], dct_y[:, :, 8:10]), axis=2),\n",
    "                                np.reshape(dct_y[:, :, 16], (28, 28, 1))), axis=2)\n",
    "\n",
    "        dct_cb = np.concatenate((dct_cb[:, :, 0:2], np.reshape(dct_cb[:, :, 8], (14, 14, 1))), axis=2)\n",
    "        dct_cr = np.concatenate((dct_cr[:, :, 0:2], np.reshape(dct_cr[:, :, 8], (14, 14, 1))), axis=2)\n",
    "        cb_cr = np.concatenate([dct_cb, dct_cr], 2)\n",
    "        positive_batch_y[j, :, :, :] = dct_y\n",
    "        positive_batch_cbcr[j, :, :, :] = cb_cr\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        x1_feature = tf.math.l2_normalize(projection_head(feature_extractor([query_batch_y, query_batch_cbcr], training=True), training=True), axis=1)\n",
    "        x2_feature = tf.math.l2_normalize(projection_head(feature_extractor([positive_batch_y, positive_batch_cbcr], training=True), training=True), axis=1)\n",
    "\n",
    "        x1_x2_mat = tf.exp(tf.matmul(x1_feature, tf.transpose(x2_feature)) / tau)\n",
    "\n",
    "        denominator = tf.reduce_sum(x1_x2_mat, 1)\n",
    "        #positive_sim = tf.linalg.diag_part(x1_x2_mat)\n",
    "        prob = x1_x2_mat / tf.reshape(denominator, (x1_feature.shape[0], 1))\n",
    "        prob = tf.linalg.diag_part(prob)\n",
    "\n",
    "        loss = -tf.reduce_mean(tf.math.log(prob))\n",
    "\n",
    "    grads = tape.gradient(loss, feature_extractor.trainable_variables + projection_head.trainable_variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, feature_extractor.trainable_variables + projection_head.trainable_variables))\n",
    "    error_list.append(loss.numpy())\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"current epoch: \", epoch,  \"current loss\", loss.numpy())\n",
    "t1 = time.perf_counter()\n",
    "print('processing time for 100 epochs',t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0a151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.save_weights(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/dct_mix/base_1\")\n",
    "projection_head.save_weights(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/dct_mix/pro_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e25e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_num_list= [3000, 2993, 3000, 3000, 3000, 3000, 3000, 2999, 3000, 3000]\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "subject_num = 10\n",
    "error_list = np.zeros((10,1))\n",
    "error_list = error_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f65c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.load_weights(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/dct_ours/base_1\")\n",
    "projection_head.load_weights(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/dct_ours/pro_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92152d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# contrastive learning\n",
    "for epoch in range(500):\n",
    "\n",
    "    subject_index = np.random.choice(subject_num, subject_num, replace=False)\n",
    "    episode = 0\n",
    "    for sub in subject_index:\n",
    "        left_landmarks = np.load(\"/home/lingyu/MPIIFaceGaze_normalized/MPIIFaceGaze_normalizad/p0\"+str(sub)+\"/left_landmarks.npy\")\n",
    "        right_landmarks = np.load(\"/home/lingyu/MPIIFaceGaze_normalized/MPIIFaceGaze_normalizad/p0\"+str(sub)+\"/right_landmarks.npy\")\n",
    "        index = np.random.choice(pic_num_list[sub], batch_size, replace=False)\n",
    "        j = 0\n",
    "        for i in index:\n",
    "            jpeg_file = '/home/lingyu/MPIIFaceGaze_normalized/MPIIFaceGaze_normalizad/p0' + str(sub) + '/' + str(i) + '.jpg'\n",
    "            img = io.imread(jpeg_file) / 255.\n",
    "            selected_trans = random.sample(trans_list, 2)\n",
    "            noised_image1 = trans_in_rgb.apply_transformation(copy.deepcopy(img), selected_trans[0], left_landmarks[i], right_landmarks[i])\n",
    "            noised_image2 = trans_in_rgb.apply_transformation(copy.deepcopy(img), selected_trans[1], left_landmarks[i], right_landmarks[i])\n",
    "\n",
    "            noised_image1 = trans_in_rgb.apply_transformation(copy.deepcopy(noised_image1), selected_trans[1], left_landmarks[i], right_landmarks[i])\n",
    "            noised_image2 = trans_in_rgb.apply_transformation(copy.deepcopy(noised_image2), selected_trans[0], left_landmarks[i], right_landmarks[i])\n",
    "        \n",
    "            noised_image1 = cv2.resize(noised_image1, (224,224))\n",
    "            noised_image2 = cv2.resize(noised_image2, (224,224))\n",
    "\n",
    "            noised_image1 *= 255\n",
    "            noised_image1 = np.round(noised_image1).astype(np.uint8)\n",
    "            noised_image2 *= 255\n",
    "            noised_image2 = np.round(noised_image2).astype(np.uint8)\n",
    "            io.imsave(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/temp_pic/noised_image1.jpg\", noised_image1)\n",
    "            io.imsave(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/temp_pic/noised_image2.jpg\", noised_image2)\n",
    "\n",
    "            jpeg_noised = \"/home/lingyu/CL_gaze_project/MPIIFaceGaze/temp_pic/noised_image1.jpg\"\n",
    "            dct_y, dct_cb, dct_cr = load(jpeg_noised)\n",
    "            # channel selection\n",
    "            dct_y = np.concatenate((np.concatenate((dct_y[:, :, 0:3], dct_y[:, :, 8:10]), axis=2),\n",
    "                                    np.reshape(dct_y[:, :, 16], (28, 28, 1))), axis=2)\n",
    "\n",
    "            dct_cb = np.concatenate((dct_cb[:, :, 0:2], np.reshape(dct_cb[:, :, 8], (14, 14, 1))), axis=2)\n",
    "            dct_cr = np.concatenate((dct_cr[:, :, 0:2], np.reshape(dct_cr[:, :, 8], (14, 14, 1))), axis=2)\n",
    "            cb_cr = np.concatenate([dct_cb, dct_cr], 2)\n",
    "            query_batch_y[j, :, :, :] = dct_y\n",
    "            query_batch_cbcr[j, :, :, :] = cb_cr\n",
    "\n",
    "            jpeg_noised = \"/home/lingyu/CL_gaze_project/MPIIFaceGaze/temp_pic/noised_image2.jpg\"\n",
    "            dct_y, dct_cb, dct_cr = load(jpeg_noised)\n",
    "            # channel selection\n",
    "            dct_y = np.concatenate((np.concatenate((dct_y[:, :, 0:3], dct_y[:, :, 8:10]), axis=2),\n",
    "                                    np.reshape(dct_y[:, :, 16], (28, 28, 1))), axis=2)\n",
    "\n",
    "            dct_cb = np.concatenate((dct_cb[:, :, 0:2], np.reshape(dct_cb[:, :, 8], (14, 14, 1))), axis=2)\n",
    "            dct_cr = np.concatenate((dct_cr[:, :, 0:2], np.reshape(dct_cr[:, :, 8], (14, 14, 1))), axis=2)\n",
    "            cb_cr = np.concatenate([dct_cb, dct_cr], 2)\n",
    "            positive_batch_y[j, :, :, :] = dct_y\n",
    "            positive_batch_cbcr[j, :, :, :] = cb_cr\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            x1_feature = tf.math.l2_normalize(projection_head(feature_extractor([query_batch_y, query_batch_cbcr], training=True), training=True), axis=1)\n",
    "            x2_feature = tf.math.l2_normalize(projection_head(feature_extractor([positive_batch_y, positive_batch_cbcr], training=True), training=True), axis=1)\n",
    "\n",
    "            x1_x2_mat = tf.exp(tf.matmul(x1_feature, tf.transpose(x2_feature)) / tau)\n",
    "\n",
    "            denominator = tf.reduce_sum(x1_x2_mat, 1)\n",
    "            #positive_sim = tf.linalg.diag_part(x1_x2_mat)\n",
    "            prob = x1_x2_mat / tf.reshape(denominator, (x1_feature.shape[0], 1))\n",
    "            prob = tf.linalg.diag_part(prob)\n",
    "\n",
    "            loss = -tf.reduce_mean(tf.math.log(prob))\n",
    "\n",
    "        grads = tape.gradient(loss, feature_extractor.trainable_variables + projection_head.trainable_variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, feature_extractor.trainable_variables + projection_head.trainable_variables))\n",
    "        episode += 1\n",
    "        error_list[sub].append(loss.numpy())\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"current epoch: \", epoch, \"current loss\", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.save_weights(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/dct_ours/base_1\")\n",
    "projection_head.save_weights(\"/home/lingyu/CL_gaze_project/MPIIFaceGaze/dct_ours/pro_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list_arr= np.array(error_list)\n",
    "for sub_fig in range(10):\n",
    "    plt.plot(error_list_arr[sub_fig][1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d206db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
